{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kinome79/Colaborator/blob/main/Copy_of_fcc_sms_text_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "8RZOuS9LWQvv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "36bafce4-c528-4400-c6eb-317653d4beab"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tensorflow-datasets in /usr/local/lib/python3.8/dist-packages (4.8.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from tensorflow-datasets) (1.22.4)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.8/dist-packages (from tensorflow-datasets) (1.15.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from tensorflow-datasets) (4.64.1)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.8/dist-packages (from tensorflow-datasets) (5.12.0)\n",
            "Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.8/dist-packages (from tensorflow-datasets) (1.12.0)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.8/dist-packages (from tensorflow-datasets) (2.2.0)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.8/dist-packages (from tensorflow-datasets) (1.4.0)\n",
            "Requirement already satisfied: dm-tree in /usr/local/lib/python3.8/dist-packages (from tensorflow-datasets) (0.1.8)\n",
            "Requirement already satisfied: promise in /usr/local/lib/python3.8/dist-packages (from tensorflow-datasets) (2.3)\n",
            "Requirement already satisfied: protobuf>=3.12.2 in /usr/local/lib/python3.8/dist-packages (from tensorflow-datasets) (3.19.6)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.8/dist-packages (from tensorflow-datasets) (5.4.8)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.8/dist-packages (from tensorflow-datasets) (0.3.6)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow-datasets) (2.25.1)\n",
            "Requirement already satisfied: toml in /usr/local/lib/python3.8/dist-packages (from tensorflow-datasets) (0.10.2)\n",
            "Requirement already satisfied: etils[enp,epath]>=0.9.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow-datasets) (1.0.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.8/dist-packages (from tensorflow-datasets) (8.1.3)\n",
            "Requirement already satisfied: zipp in /usr/local/lib/python3.8/dist-packages (from etils[enp,epath]>=0.9.0->tensorflow-datasets) (3.15.0)\n",
            "Requirement already satisfied: typing_extensions in /usr/local/lib/python3.8/dist-packages (from etils[enp,epath]>=0.9.0->tensorflow-datasets) (4.5.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->tensorflow-datasets) (1.26.14)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->tensorflow-datasets) (2022.12.7)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->tensorflow-datasets) (4.0.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->tensorflow-datasets) (2.10)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from promise->tensorflow-datasets) (1.15.0)\n",
            "Requirement already satisfied: googleapis-common-protos<2,>=1.52.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow-metadata->tensorflow-datasets) (1.58.0)\n",
            "2.11.0\n"
          ]
        }
      ],
      "source": [
        "# import libraries\n",
        "#try:\n",
        "  # %tensorflow_version only exists in Colab.\n",
        "#  !pip install tf-nightly\n",
        "#except Exception:\n",
        "#  pass\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "from tensorflow import keras\n",
        "!pip install tensorflow-datasets\n",
        "import tensorflow_datasets as tfds\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "print(tf.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "lMHwYXHXCar3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "57306ab9-dc45-42e8-b0f8-9df4cad3deca"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-02-28 18:42:58--  https://cdn.freecodecamp.org/project-data/sms/train-data.tsv\n",
            "Resolving cdn.freecodecamp.org (cdn.freecodecamp.org)... 104.26.3.33, 104.26.2.33, 172.67.70.149, ...\n",
            "Connecting to cdn.freecodecamp.org (cdn.freecodecamp.org)|104.26.3.33|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 358233 (350K) [text/tab-separated-values]\n",
            "Saving to: ‘train-data.tsv.1’\n",
            "\n",
            "train-data.tsv.1    100%[===================>] 349.84K  2.03MB/s    in 0.2s    \n",
            "\n",
            "2023-02-28 18:42:58 (2.03 MB/s) - ‘train-data.tsv.1’ saved [358233/358233]\n",
            "\n",
            "--2023-02-28 18:42:58--  https://cdn.freecodecamp.org/project-data/sms/valid-data.tsv\n",
            "Resolving cdn.freecodecamp.org (cdn.freecodecamp.org)... 104.26.3.33, 104.26.2.33, 172.67.70.149, ...\n",
            "Connecting to cdn.freecodecamp.org (cdn.freecodecamp.org)|104.26.3.33|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 118774 (116K) [text/tab-separated-values]\n",
            "Saving to: ‘valid-data.tsv.1’\n",
            "\n",
            "valid-data.tsv.1    100%[===================>] 115.99K  --.-KB/s    in 0.06s   \n",
            "\n",
            "2023-02-28 18:42:59 (1.79 MB/s) - ‘valid-data.tsv.1’ saved [118774/118774]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# get data files\n",
        "!wget https://cdn.freecodecamp.org/project-data/sms/train-data.tsv\n",
        "!wget https://cdn.freecodecamp.org/project-data/sms/valid-data.tsv\n",
        "\n",
        "train_file_path = \"train-data.tsv\"\n",
        "test_file_path = \"valid-data.tsv\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "g_h508FEClxO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "88079706-632c-46c3-c4ca-3709328c0279"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train DataFrame ----------------------------------------\n",
            "\n",
            "      type                                            message\n",
            "0      ham  ahhhh...just woken up!had a bad dream about u ...\n",
            "1      ham                           you can never do nothing\n",
            "2      ham  now u sound like manky scouse boy steve,like! ...\n",
            "3      ham  mum say we wan to go then go... then she can s...\n",
            "4      ham  never y lei... i v lazy... got wat? dat day ü ...\n",
            "...    ...                                                ...\n",
            "4174   ham  just woke up. yeesh its late. but i didn't fal...\n",
            "4175   ham  what do u reckon as need 2 arrange transport i...\n",
            "4176  spam  free entry into our £250 weekly competition ju...\n",
            "4177  spam  -pls stop bootydelious (32/f) is inviting you ...\n",
            "4178   ham  tell my  bad character which u dnt lik in me. ...\n",
            "\n",
            "[4179 rows x 2 columns]\n",
            "\n",
            "Test DataFrame ----------------------------------------\n",
            "\n",
            "      type                                            message\n",
            "0      ham  i am in hospital da. . i will return home in e...\n",
            "1      ham         not much, just some textin'. how bout you?\n",
            "2      ham  i probably won't eat at all today. i think i'm...\n",
            "3      ham  don‘t give a flying monkeys wot they think and...\n",
            "4      ham                                who are you seeing?\n",
            "...    ...                                                ...\n",
            "1387   ham  true dear..i sat to pray evening and felt so.s...\n",
            "1388   ham               what will we do in the shower, baby?\n",
            "1389   ham  where are you ? what are you doing ? are yuou ...\n",
            "1390  spam  ur cash-balance is currently 500 pounds - to m...\n",
            "1391  spam  not heard from u4 a while. call 4 rude chat pr...\n",
            "\n",
            "[1392 rows x 2 columns]\n"
          ]
        }
      ],
      "source": [
        "# create datasets with the imported data\n",
        "df_train = pd.read_csv(train_file_path, delimiter='\\t', names=['type', 'message'])\n",
        "df_test = pd.read_csv(test_file_path, delimiter='\\t', names=['type', 'message'])\n",
        "\n",
        "print ('Train DataFrame ----------------------------------------\\n\\n' + str(df_train))\n",
        "print ('\\nTest DataFrame ----------------------------------------\\n\\n' + str(df_test))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "zOMKywn4zReN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "31436d43-eb12-49f5-c171-7726877ae4ad"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Are there any null values in df_train: [False False]\n",
            "Are there any null values in df_test: [False False]\n",
            "\n",
            "What are values for type in df_train: ['ham' 'spam']\n",
            "What are the values for type in df_test: ['ham' 'spam']\n",
            "\n",
            "Labels are 0=ham and 1=spam. Categories = ['ham' 'spam']\n"
          ]
        }
      ],
      "source": [
        "# Verify no null values, and what unique values are in the type column\n",
        "\n",
        "print('Are there any null values in df_train:', pd.isna(df_train).any().values)\n",
        "print('Are there any null values in df_test:', pd.isna(df_test).any().values)\n",
        "print('\\nWhat are values for type in df_train:', df_train['type'].unique())\n",
        "print('What are the values for type in df_test:', df_test['type'].unique())\n",
        "\n",
        "categories = df_train['type'].unique()\n",
        "print('\\nLabels are 0=ham and 1=spam. Categories =', categories)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert type to numeric 0/1 values\n",
        "\n",
        "df_train['type'].replace(['ham','spam'], [0,1], inplace=True)\n",
        "df_test['type'].replace(['ham','spam'], [0,1], inplace=True)\n",
        "\n",
        "print (df_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YSt-iX2P_q2T",
        "outputId": "81ec02bf-bfb9-4597-db3d-1c7f7ad2e3a3"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      type                                            message\n",
            "0        0  ahhhh...just woken up!had a bad dream about u ...\n",
            "1        0                           you can never do nothing\n",
            "2        0  now u sound like manky scouse boy steve,like! ...\n",
            "3        0  mum say we wan to go then go... then she can s...\n",
            "4        0  never y lei... i v lazy... got wat? dat day ü ...\n",
            "...    ...                                                ...\n",
            "4174     0  just woke up. yeesh its late. but i didn't fal...\n",
            "4175     0  what do u reckon as need 2 arrange transport i...\n",
            "4176     1  free entry into our £250 weekly competition ju...\n",
            "4177     1  -pls stop bootydelious (32/f) is inviting you ...\n",
            "4178     0  tell my  bad character which u dnt lik in me. ...\n",
            "\n",
            "[4179 rows x 2 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Separate the data labels from the data\n",
        "train_labels = df_train.pop('type').values\n",
        "test_labels = df_test.pop('type').values\n",
        "\n",
        "# Make the data an array instead of dataframe\n",
        "train_data = df_train.values\n",
        "test_data = df_test.values\n",
        "\n",
        "print('Train Data ------------------------------------\\n')\n",
        "print(train_data)\n",
        "print('\\nTrain Label ---------------------------------------\\n')\n",
        "print(train_labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1jAeez9IDeuR",
        "outputId": "5479040f-772d-477e-83fa-b4d5adcefc43"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Data ------------------------------------\n",
            "\n",
            "[['ahhhh...just woken up!had a bad dream about u tho,so i dont like u right now :) i didnt know anything about comedy night but i guess im up for it.']\n",
            " ['you can never do nothing']\n",
            " ['now u sound like manky scouse boy steve,like! i is travelling on da bus home.wot has u inmind 4 recreation dis eve?']\n",
            " ...\n",
            " ['free entry into our £250 weekly competition just text the word win to 80086 now. 18 t&c www.txttowin.co.uk']\n",
            " ['-pls stop bootydelious (32/f) is inviting you to be her friend. reply yes-434 or no-434 see her: www.sms.ac/u/bootydelious stop? send stop frnd to 62468']\n",
            " [\"tell my  bad character which u dnt lik in me. i'll try to change in  &lt;#&gt; . i ll add tat 2 my new year resolution. waiting for ur reply.be frank...good morning.\"]]\n",
            "\n",
            "Train Label ---------------------------------------\n",
            "\n",
            "[0 0 0 ... 1 1 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create Vocab Dict and functions to encode/decode strings \n",
        "\n",
        "import re\n",
        "\n",
        "#create vocab variable to store all words, and their integer encoding\n",
        "vocab = {'-':0} # make index 0 a non-used char... not sure if padding strings with 0's would effect if index 0 was a\n",
        "\n",
        "# encode_text function - takes a string, and returns an array of numbers, adds to vocab dict \n",
        "def encode_text (mystring):\n",
        "\n",
        "  #split string into array of lowercase words, removing punc but leaving @,!,$,?\n",
        "  words = re.split(r'[., \"\\'(){}%&*+-]+', re.sub(r'([@!$?])', r' \\1 ', mystring))\n",
        "  nums = []\n",
        "\n",
        "  # for each word, convert to int, adding to vocab if needed\n",
        "  for word in words:\n",
        "    word = word.lower()\n",
        "\n",
        "    if word: # if not blank\n",
        "      if word not in vocab:\n",
        "        vocab[word] = len(vocab)\n",
        "      nums.append(vocab[word])\n",
        "\n",
        "  return nums\n",
        "\n",
        "\n",
        "# decode_text function - takes array of numbers, returns array of words from vocab dict\n",
        "def decode_text (myarray):\n",
        "\n",
        "  # inverse the vocab dictionary and decode text\n",
        "  inv_vocab = {val:key for key,val in vocab.items()}\n",
        "  new_array = [inv_vocab[num] for num in myarray]\n",
        "\n",
        "  return myarray\n"
      ],
      "metadata": {
        "id": "zrUk6voTFGpd"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Encode all strings to use in our analysis\n",
        "train_data_encoded = [encode_text(arr[0]) for arr in train_data]\n",
        "test_data_encoded = [encode_text(arr[0]) for arr in test_data]\n",
        "\n",
        "print('Train Data Encoded ------------------------------------\\n')\n",
        "print(train_data_encoded[:5])\n",
        "print('\\nTest Data Encoded ------------------------------------\\n')\n",
        "print(test_data_encoded[:5])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "im5LK9XjK-vR",
        "outputId": "f0045cc4-d68f-456f-facb-bd5c9760c44c"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Data Encoded ------------------------------------\n",
            "\n",
            "[[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 11, 17, 18, 19, 14, 20, 21, 22, 10, 23, 24, 25, 14, 26, 27, 4, 28, 29], [30, 31, 32, 33, 34], [18, 11, 35, 16, 36, 37, 38, 39, 16, 5, 14, 40, 41, 42, 43, 44, 45, 46, 47, 11, 48, 49, 50, 51, 52, 53], [54, 55, 56, 57, 58, 59, 60, 59, 60, 61, 31, 62, 63, 64, 43, 65, 66], [32, 67, 68, 14, 69, 70, 71, 72, 53, 73, 74, 75, 76, 77, 43, 78, 79, 80, 81]]\n",
            "\n",
            "Test Data Encoded ------------------------------------\n",
            "\n",
            "[[14, 300, 82, 2661, 43, 14, 269, 1839, 45, 82, 2077], [301, 531, 2, 335, 7850, 111, 1991, 30, 53], [14, 845, 924, 138, 715, 203, 197, 288, 14, 775, 14, 247, 388, 6667, 111, 240, 112, 406, 53, 307, 11, 417, 77, 53], [6432, 231, 7, 7851, 7852, 46, 118, 775, 156, 14, 6223, 6432, 424, 892, 340, 98, 1226, 156, 197, 148, 5], [789, 229, 30, 1533, 53]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Find the average and maximum lenghts of the data strings to decide how the data should be padded\n",
        "\n",
        "print(\"Average length of train strings is:\", sum(len(arr) for arr in train_data_encoded)/len(train_data_encoded))\n",
        "print(\"Max lengh of test strings is:\", max(len(arr) for arr in train_data_encoded))\n",
        "print(\"# of train strings  with len > 100 is:\", sum(1 if len(arr) > 100 else 0 for arr in train_data_encoded))\n",
        "\n",
        "print(\"\\nAverage length of test strings is:\", sum(len(arr) for arr in test_data_encoded)/len(test_data_encoded))\n",
        "print(\"Max lengh of test strings is:\", max(len(arr) for arr in test_data_encoded))\n",
        "print(\"# of test strings  with len > 100 is:\", sum(1 if len(arr) > 100 else 0 for arr in test_data_encoded))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SR9k5WKgGDuh",
        "outputId": "c9794697-13a1-4146-f29d-88574640f7df"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average length of train strings is: 16.704953338119168\n",
            "Max lengh of test strings is: 190\n",
            "# of train strings  with len > 100 is: 5\n",
            "\n",
            "Average length of test strings is: 16.6558908045977\n",
            "Max lengh of test strings is: 101\n",
            "# of test strings  with len > 100 is: 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Padding sequences to the length of the 100, which will crop 6 entries but not have excessive padding\n",
        "\n",
        "data_length = 100\n",
        "\n",
        "train_data_encoded = keras.utils.pad_sequences(train_data_encoded, data_length)\n",
        "test_data_encoded = keras.utils.pad_sequences(test_data_encoded, data_length)\n",
        "\n",
        "print(test_data_encoded[:2])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NqBsrUQ8YwBU",
        "outputId": "2ce3a1dc-f123-4e63-e591-19f80f91117a"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0   14  300   82 2661   43   14  269 1839   45\n",
            "    82 2077]\n",
            " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0  301  531    2  335 7850  111 1991\n",
            "    30   53]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# As I built my own vocab, need to determine how I want to set the input dim for the model (max possible vocab for a while)\n",
        "print('Current number of words is', len(vocab))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LTaNERdBhL4c",
        "outputId": "7b28970d-d871-49ed-e9cd-aa874f1273a2"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Current number of words is 9199\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create and compile model for analysis.\n",
        "\n",
        "MAX_VOCAB_LENGTH = 10200  # Based on above numbers, this will allow addition of 1001 to vocab if needed\n",
        "\n",
        "# Create the Sequential model\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(\n",
        "        input_dim = 10200, \n",
        "        mask_zero = True, \n",
        "        input_length = data_length,\n",
        "        output_dim = 64),   \n",
        "    tf.keras.layers.LSTM(64),       \n",
        "    tf.keras.layers.Dense(1, activation=\"sigmoid\")\n",
        "])\n",
        "\n",
        "model.compile(loss=\"binary_crossentropy\", optimizer=\"rmsprop\", metrics=['acc'])\n"
      ],
      "metadata": {
        "id": "GRYIYhFTLCBZ"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "\n",
        "history = model.fit(train_data_encoded, train_labels, epochs=10, validation_split=0.2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pCELeQirLPHJ",
        "outputId": "9a4e5afe-1107-485b-d0ef-a79d56f772a9"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "105/105 [==============================] - 19s 121ms/step - loss: 0.2738 - acc: 0.9189 - val_loss: 0.1013 - val_acc: 0.9785\n",
            "Epoch 2/10\n",
            "105/105 [==============================] - 10s 99ms/step - loss: 0.0686 - acc: 0.9812 - val_loss: 0.0576 - val_acc: 0.9868\n",
            "Epoch 3/10\n",
            "105/105 [==============================] - 11s 107ms/step - loss: 0.0393 - acc: 0.9895 - val_loss: 0.0601 - val_acc: 0.9844\n",
            "Epoch 4/10\n",
            "105/105 [==============================] - 10s 99ms/step - loss: 0.0266 - acc: 0.9934 - val_loss: 0.0637 - val_acc: 0.9797\n",
            "Epoch 5/10\n",
            "105/105 [==============================] - 10s 97ms/step - loss: 0.0160 - acc: 0.9973 - val_loss: 0.0491 - val_acc: 0.9880\n",
            "Epoch 6/10\n",
            "105/105 [==============================] - 10s 93ms/step - loss: 0.0131 - acc: 0.9961 - val_loss: 0.0452 - val_acc: 0.9904\n",
            "Epoch 7/10\n",
            "105/105 [==============================] - 10s 100ms/step - loss: 0.0063 - acc: 0.9994 - val_loss: 0.0625 - val_acc: 0.9856\n",
            "Epoch 8/10\n",
            "105/105 [==============================] - 11s 101ms/step - loss: 0.0090 - acc: 0.9979 - val_loss: 0.0554 - val_acc: 0.9880\n",
            "Epoch 9/10\n",
            "105/105 [==============================] - 11s 101ms/step - loss: 0.0046 - acc: 0.9994 - val_loss: 0.0623 - val_acc: 0.9868\n",
            "Epoch 10/10\n",
            "105/105 [==============================] - 11s 104ms/step - loss: 0.0028 - acc: 0.9994 - val_loss: 0.0797 - val_acc: 0.9856\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Verify if the model was successful\n",
        "\n",
        "results = model.evaluate(test_data_encoded, test_labels)\n",
        "print(results)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JGoeioavLm5t",
        "outputId": "12c14c91-94e2-4784-8554-6dff5a2bc0b1"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "44/44 [==============================] - 1s 27ms/step - loss: 0.0776 - acc: 0.9864\n",
            "[0.07764226198196411, 0.9863505959510803]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "id": "J9tD9yACG6M9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "86e787df-75a6-43b0-dd0b-0d7cb82cfe3c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 32ms/step\n",
            "[3.84491e-05, 'ham']\n"
          ]
        }
      ],
      "source": [
        "# function to predict messages based on model\n",
        "# (should return list containing prediction and label, ex. [0.008318834938108921, 'ham'])\n",
        "def predict_message(pred_text):\n",
        "  \n",
        "  encoded_text = keras.utils.pad_sequences( [encode_text(pred_text)], data_length )\n",
        "  prediction = model.predict(encoded_text)\n",
        "  prediction = [prediction[0][0], categories[round(prediction[0][0])]]\n",
        "\n",
        "\n",
        "  return (prediction)\n",
        "\n",
        "pred_text = \"how are you doing today?\"\n",
        "\n",
        "prediction = predict_message(pred_text)\n",
        "print(prediction)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "id": "Dxotov85SjsC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8e93d7d4-4518-4f4d-95ee-9bbeec332cff"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "You passed the challenge. Great job!\n"
          ]
        }
      ],
      "source": [
        "# Run this cell to test your function and model. Do not modify contents.\n",
        "def test_predictions():\n",
        "  test_messages = [\"how are you doing today\",\n",
        "                   \"sale today! to stop texts call 98912460324\",\n",
        "                   \"i dont want to go. can we try it a different day? available sat\",\n",
        "                   \"our new mobile video service is live. just install on your phone to start watching.\",\n",
        "                   \"you have won £1000 cash! call to claim your prize.\",\n",
        "                   \"i'll bring it tomorrow. don't forget the milk.\",\n",
        "                   \"wow, is your arm alright. that happened to me one time too\"\n",
        "                  ]\n",
        "\n",
        "  test_answers = [\"ham\", \"spam\", \"ham\", \"spam\", \"spam\", \"ham\", \"ham\"]\n",
        "  passed = True\n",
        "\n",
        "  for msg, ans in zip(test_messages, test_answers):\n",
        "    prediction = predict_message(msg)\n",
        "    if prediction[1] != ans:\n",
        "      passed = False\n",
        "\n",
        "  if passed:\n",
        "    print(\"You passed the challenge. Great job!\")\n",
        "  else:\n",
        "    print(\"You haven't passed yet. Keep trying.\")\n",
        "\n",
        "test_predictions()\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {},
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}